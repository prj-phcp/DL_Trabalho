{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun  9 17:40:10 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.43.04    Driver Version: 515.43.04    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:15:00.0 Off |                    0 |\n",
      "| N/A   30C    P0    53W / 300W |   5977MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      5568      C   .../venvs/dl_raul/bin/python     2177MiB |\n",
      "|    0   N/A  N/A     25706      C   .../venvs/dl_raul/bin/python     3797MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Dispositivo onde tensores serão criados, armazenados e processados\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "# Randon Seed fixa para resultados reprodutíveis\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WellLoader(Dataset):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 path, \n",
    "                 wells, \n",
    "                 var_in, \n",
    "                 var_out, \n",
    "                 normalizing_split=0.2, \n",
    "                 normalizer=RobustScaler, \n",
    "                 max_sequence=16, \n",
    "                 step=1):\n",
    "        \n",
    "        self.path = path\n",
    "        with open(self.path + '/metadata.json', 'r') as metafile:\n",
    "            self.metadata = json.loads(metafile.read())\n",
    "        self.wells = wells\n",
    "        self.var_in = var_in\n",
    "        self.var_out = var_out\n",
    "        self.normalizing_split = normalizing_split\n",
    "        self.normalizer = normalizer\n",
    "        self.max_sequence = max_sequence\n",
    "        self.step = step\n",
    "        self.batches_X = None\n",
    "        self.batches_Y = None\n",
    "        self.outputs = None\n",
    "        self.normalizers = []\n",
    "        \n",
    "        indexes = self.get_wells_index(self.wells)\n",
    "        self.load_data_by_index(indexes)\n",
    "        \n",
    "    def get_wells_index(self, wells):\n",
    "        \n",
    "        indexes = []\n",
    "        for well, filt in wells:\n",
    "            indexes.extend([(meta['INDEX'], filt) for meta in self.metadata if meta['WELL'] == well])\n",
    "        return indexes\n",
    "    \n",
    "    def load_data_by_index(self, indexes):\n",
    "        \n",
    "        batches_X = []\n",
    "        batches_Y = []\n",
    "        outputs = []\n",
    "        for index, filt in indexes:\n",
    "            data = pd.read_json(f'{self.path}/{index}.json')#.reset_index()\n",
    "            # Armengue: Por liq vol para preencher o dataset\n",
    "            data['BORE_LIQ_VOL'] = data['BORE_OIL_VOL'] + data['BORE_WAT_VOL']\n",
    "            data = data[self.var_in + self.var_out].dropna().reset_index(drop=True)\n",
    "            X = data[self.var_in].values[filt,:]\n",
    "            Y = data[self.var_out].values[filt,:]\n",
    "            #X_base, _, Y_base, _ = train_test_split(X, Y, test_size = self.normalizing_split)\n",
    "            #scaler_X = self.normalizer().fit(X_base)\n",
    "            #scaler_Y = self.normalizer().fit(Y_base)\n",
    "            #self.normalizers.append((scaler_X, scaler_Y))\n",
    "            #X, Y = scaler_X.transform(X), scaler_Y.transform(Y)\n",
    "            X, Y = torch.from_numpy(X.astype('float32')), torch.from_numpy(Y.astype('float32'))\n",
    "            output = Y[self.max_sequence::self.step]\n",
    "            #print(Y.shape)\n",
    "            #X = torch.split(X, self.max_sequence, dim= 0)\n",
    "            #Y = torch.split(Y, self.max_sequence, dim= 0)\n",
    "            X = X.unfold(0,self.max_sequence, self.step)\n",
    "            Y = Y.unfold(0,self.max_sequence, self.step)\n",
    "            batches_X.append(X)\n",
    "            batches_Y.append(Y)\n",
    "            outputs.append(output)\n",
    "            #print(X.shape)\n",
    "        self.batches_X = torch.concat(batches_X, axis=0)\n",
    "        self.batches_Y = torch.concat(batches_Y, axis=0)\n",
    "        self.outputs = torch.concat(outputs, axis=0)\n",
    "            \n",
    "    def __len__(self):\n",
    "        \n",
    "        return self.outputs.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "                        \n",
    "        srcs = self.batches_X[idx,:,:]\n",
    "        trgts = self.batches_Y[idx,:,:]\n",
    "        output = self.outputs[idx,:]\n",
    "        \n",
    "        return srcs, trgts, output\n",
    "        \n",
    "        \n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = './dataset/volve'\n",
    "wells = [\n",
    "    ('15/9-F-1 C', slice(28, None)),\n",
    "]\n",
    "\n",
    "var_in = [\n",
    "        'AVG_DOWNHOLE_PRESSURE',\n",
    "        'AVG_WHP_P',\n",
    "        'AVG_CHOKE_SIZE_P',\n",
    "        'AVG_WHT_P',\n",
    "        'AVG_DOWNHOLE_TEMPERATURE',\n",
    "]\n",
    "\n",
    "var_out = [\n",
    "        #'BORE_OIL_VOL',\n",
    "        'BORE_LIQ_VOL',\n",
    "        #'BORE_GAS_VOL',\n",
    "        #'BORE_WAT_VOL',\n",
    "]\n",
    "\n",
    "\n",
    "dataset = WellLoader(path, wells, var_in, var_out, max_sequence = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SubsetSplitter:\n",
    "    \n",
    "    def __init__(self, batch_size, validation_split, test_split, shuffle=False):\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.validation_split = validation_split\n",
    "        self.test_split = test_split\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "    def __call__(self, dataset:Dataset):\n",
    "        \n",
    "        dataset_size = len(dataset)\n",
    "        indices = list(range(dataset_size))\n",
    "        validation_split = int(np.floor(self.validation_split * dataset_size))\n",
    "        test_split = int(np.floor(self.test_split * dataset_size))\n",
    "        train_split = dataset_size - validation_split - test_split\n",
    "        if self.shuffle :\n",
    "            np.random.shuffle(indices)\n",
    "        train_indices = indices[:train_split]\n",
    "        validation_indices = indices[train_split:train_split + validation_split]\n",
    "        test_indices = indices[train_split + validation_split:]\n",
    "\n",
    "        # Creating PT data samplers and loaders:\n",
    "        train_sampler = SubsetRandomSampler(train_indices)\n",
    "        valid_sampler = SubsetRandomSampler(validation_indices)\n",
    "        test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(dataset, batch_size=self.batch_size, \n",
    "                                                   sampler=train_sampler)\n",
    "        validation_loader = torch.utils.data.DataLoader(dataset, batch_size=self.batch_size,\n",
    "                                                    sampler=valid_sampler)\n",
    "        test_loader = torch.utils.data.DataLoader(dataset, batch_size=self.batch_size,\n",
    "                                                    sampler=test_sampler)\n",
    "        \n",
    "        return train_loader, validation_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "splitter = SubsetSplitter(8, 0.2, 0.2)\n",
    "train_loader, validation_loader, test_loader = splitter(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.0000, 1.4286, 0.0000, 1.4286, 0.0000, 1.4286,\n",
       "          0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.4286, 0.0000, 0.0000,\n",
       "          0.0000, 1.4286]]])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, dim_model, dropout_p, max_len):\n",
    "        super().__init__()\n",
    "        # Modified version from: https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
    "        # max_len determines how far the position can have an effect on a token (window)\n",
    "        \n",
    "        # Info\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        \n",
    "        # Encoding - From formula\n",
    "        pos_encoding = torch.zeros(max_len, dim_model)\n",
    "        positions_list = torch.arange(0, max_len, dtype=torch.float).view(-1, 1) # 0, 1, 2, 3, 4, 5\n",
    "        division_term = torch.exp(torch.arange(0, dim_model, 2).float() * (-math.log(10000.0)) / dim_model) # 1000^(2i/dim_model)\n",
    "        \n",
    "        # PE(pos, 2i) = sin(pos/1000^(2i/dim_model))\n",
    "        pos_encoding[:, 0::2] = torch.sin(positions_list * division_term)\n",
    "        \n",
    "        # PE(pos, 2i + 1) = cos(pos/1000^(2i/dim_model))\n",
    "        pos_encoding[:, 1::2] = torch.cos(positions_list * division_term)\n",
    "        \n",
    "        # Saving buffer (same as parameter without gradients needed)\n",
    "        pos_encoding = pos_encoding.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer(\"pos_encoding\",pos_encoding)\n",
    "        \n",
    "    def forward(self, token_embedding: torch.tensor) -> torch.tensor:\n",
    "        # Residual connection + pos encoding\n",
    "        return self.dropout(token_embedding + self.pos_encoding[:token_embedding.size(0), :])\n",
    "    \n",
    "    \n",
    "positional_encoding = PositionalEncoding(dim_model = 10, dropout_p=0.3, max_len=1200)\n",
    "tensor = torch.zeros((1,2,10))\n",
    "tensor\n",
    "encoded = positional_encoding(tensor)\n",
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Model from \"A detailed guide to Pytorch's nn.Transformer() module.\", by\n",
    "    Daniel Melchor: https://medium.com/@danielmelchor/a-detailed-guide-to-pytorchs-nn-transformer-module-c80afbc9ffb1\n",
    "    \"\"\"\n",
    "    # Constructor\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_outputs,\n",
    "        dim_model,\n",
    "        num_heads,\n",
    "        num_encoder_layers,\n",
    "        num_decoder_layers,\n",
    "        dropout_p,\n",
    "        num_linear_layers=0,\n",
    "        norm_first=False\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # INFO\n",
    "        self.model_type = \"Transformer\"\n",
    "        self.dim_model = dim_model\n",
    "\n",
    "        # LAYERS\n",
    "        self.positional_encoder = PositionalEncoding(\n",
    "            dim_model=dim_model, dropout_p=dropout_p, max_len=5000\n",
    "        )\n",
    "        #self.embedding = nn.Embedding(num_outputs, dim_model)\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=dim_model,\n",
    "            nhead=num_heads,\n",
    "            num_encoder_layers=num_encoder_layers,\n",
    "            num_decoder_layers=num_decoder_layers,\n",
    "            dropout=dropout_p, \n",
    "            batch_first=True,\n",
    "            norm_first = norm_first\n",
    "        )\n",
    "        self.linear_layers = nn.ModuleList()\n",
    "        for i in range(num_linear_layers):\n",
    "            self.linear_layers.append(nn.Linear(dim_model, dim_model))\n",
    "            self.linear_layers.append(nn.ReLU6())\n",
    "        self.out = nn.Linear(dim_model, num_outputs)\n",
    "        self.bias_layer = nn.Linear(dim_model, dim_model)\n",
    "        \n",
    "    def forward(self, src, tgt, tgt_mask=None, src_pad_mask=None, tgt_pad_mask=None):\n",
    "        # Src size must be (batch_size, src sequence length)\n",
    "        # Tgt size must be (batch_size, tgt sequence length)\n",
    "\n",
    "        # Embedding + positional encoding - Out size = (batch_size, sequence length, dim_model)\n",
    "        #src = self.embedding(src) * math.sqrt(self.dim_model)\n",
    "        #tgt = self.embedding(tgt) * math.sqrt(self.dim_model)\n",
    "        src_corr = src #* math.sqrt(self.dim_model)\n",
    "        tgt_corr = tgt #* math.sqrt(self.dim_model)\n",
    "        #src_corr = self.positional_encoder(src_corr)\n",
    "        #tgt_corr = self.positional_encoder(tgt_corr)\n",
    "        \n",
    "        # We could use the parameter batch_first=True, but our KDL version doesn't support it yet, so we permute\n",
    "        # to obtain size (sequence length, batch_size, dim_model),\n",
    "        #src = src.permute(1,0,2)\n",
    "        #tgt = tgt.permute(1,0,2)\n",
    "\n",
    "        # Transformer blocks - Out size = (sequence length, batch_size, num_tokens)\n",
    "        transformer_out = self.transformer(src_corr, tgt_corr, tgt_mask=tgt_mask, src_key_padding_mask=src_pad_mask, tgt_key_padding_mask=tgt_pad_mask)\n",
    "        for linear in self.linear_layers:\n",
    "            transformer_out = linear(transformer_out)\n",
    "        out = transformer_out\n",
    "        \n",
    "        #recuperando informacao de escala\n",
    "        out = torch.mul(out, tgt)\n",
    "        bias = self.bias_layer(tgt)\n",
    "        out = torch.add(out, bias)\n",
    "        \n",
    "        out = self.out(out)\n",
    "        \n",
    "        \n",
    "        return out\n",
    "      \n",
    "    def get_tgt_mask(self, size) -> torch.tensor:\n",
    "        # Generates a squeare matrix where the each row allows one word more to be seen\n",
    "        mask = torch.tril(torch.ones(size, size) == 1) # Lower triangular matrix\n",
    "        mask = mask.float()\n",
    "        mask = mask.masked_fill(mask == 0, float('-inf')) # Convert zeros to -inf\n",
    "        mask = mask.masked_fill(mask == 1, float(0.0)) # Convert ones to 0\n",
    "        \n",
    "        # EX for size=5:\n",
    "        # [[0., -inf, -inf, -inf, -inf],\n",
    "        #  [0.,   0., -inf, -inf, -inf],\n",
    "        #  [0.,   0.,   0., -inf, -inf],\n",
    "        #  [0.,   0.,   0.,   0., -inf],\n",
    "        #  [0.,   0.,   0.,   0.,   0.]]\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    def create_pad_mask(self, matrix: torch.tensor, pad_token: int) -> torch.tensor:\n",
    "        # If matrix = [1,2,3,0,0,0] where pad_token=0, the result mask is\n",
    "        # [False, False, False, True, True, True]\n",
    "        return (matrix == pad_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Training:\n",
    "    \n",
    "    def __init__(self, epochs, loss, optimizer, scheduler, path, patience=5):\n",
    "        \n",
    "        self.loss = loss\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.epochs = epochs\n",
    "        self.path = path\n",
    "        self.patience = patience\n",
    "        self.clear_results()\n",
    "        \n",
    "    def clear_results(self):\n",
    "        \n",
    "        self.results = {\n",
    "            'Train':[],\n",
    "            'Validation':[],\n",
    "            'Test':[],\n",
    "        }\n",
    "        \n",
    "    def fit(self, model, train_loader, validation_loader, test_loader):\n",
    "        \n",
    "        self.clear_results()\n",
    "        torch.cuda.empty_cache()\n",
    "        decrease = self.patience\n",
    "        not_improved = 0\n",
    "        \n",
    "        model.to(device)\n",
    "        fit_time = time.time()\n",
    "        \n",
    "        for e in range(self.epochs):\n",
    "            since = time.time()\n",
    "            running_loss = 0\n",
    "            #training loop\n",
    "            model.train()\n",
    "            self.train_loop(model, train_loader)\n",
    "            model.eval()\n",
    "            self.validation_loop(model, validation_loader)\n",
    "            self.test_loop(model, test_loader)\n",
    "            decrease, not_improved = self.early_stopping(validation_loader, decrease)\n",
    "            if not_improved == 1:\n",
    "                break\n",
    "            loss_per_training_batch = self.results['Train'][-1]\n",
    "            loss_per_validation_batch = self.results['Validation'][-1]\n",
    "            loss_per_test_batch = self.results['Test'][-1]\n",
    "            print(\"Epoch:{}/{}..\".format(e+1, self.epochs),\n",
    "                  \"Train Loss: {:.3f}..\".format(loss_per_training_batch),\n",
    "                  \"Val Loss: {:.3f}..\".format(loss_per_validation_batch),\n",
    "                  \"Test Loss: {:.3f}..\".format(loss_per_test_batch),\n",
    "                  \"Time: {:.2f}m\".format((time.time()-since)/60))\n",
    "        print('Total time: {:.2f} m' .format((time.time()- fit_time)/60))\n",
    "        \n",
    "    def train_loop(self, model, train_loader):\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(tqdm(train_loader)):\n",
    "            #training phase\n",
    "            X, y_tgt, y_out = data\n",
    "            X, y_tgt, y_out = X.to(device), y_tgt.to(device), y_out.to(device)\n",
    "            #y_result, y_tgt = Y, torch.from_numpy(-1.0*np.ones(Y.shape).astype('float32')).to(device)\n",
    "            #y_tgt[:,:,1:] = Y[:,:,:-1]\n",
    "            #y_tgt[:,:,0] = 0.0\n",
    "            output = model(X, y_tgt)\n",
    "            loss = self.loss(output.ravel(), y_out.ravel())\n",
    "            #backward\n",
    "            loss.backward()\n",
    "            self.optimizer.step() #update weight          \n",
    "            self.optimizer.zero_grad() #reset gradient\n",
    "            \n",
    "            #step the learning rate\n",
    "            if not self.scheduler is None:\n",
    "                self.scheduler.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        self.results['Train'].append(running_loss/len(train_loader))\n",
    "    \n",
    "    \n",
    "    def validation_loop(self, model, validation_loader):\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(tqdm(validation_loader)):\n",
    "                #training phase\n",
    "                X, y_tgt, y_out = data\n",
    "                X, y_tgt, y_out = X.to(device), y_tgt.to(device), y_out.to(device)\n",
    "                #y_result, y_tgt = Y, torch.from_numpy(-1.0*np.ones(Y.shape).astype('float32')).to(device)\n",
    "                #y_tgt[:,:,1:] = Y[:,:,:-1]\n",
    "                #y_tgt[:,:,0] = 0.0\n",
    "                output = model(X, y_tgt)\n",
    "                loss = self.loss(output.ravel(), y_out.ravel())\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "        \n",
    "        self.results['Validation'].append(running_loss/len(validation_loader))\n",
    "        \n",
    "    def test_loop(self, model, test_loader):\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(tqdm(test_loader)):\n",
    "                #training phase\n",
    "                X, y_tgt, y_out = data\n",
    "                X, y_tgt, y_out = X.to(device), y_tgt.to(device), y_out.to(device)\n",
    "                #y_result, y_tgt = Y, torch.from_numpy(-1.0*np.ones(Y.shape).astype('float32')).to(device)\n",
    "                #y_tgt[:,:,1:] = Y[:,:,:-1]\n",
    "                #y_tgt[:,:,0] = 0.0\n",
    "                output = model(X, y_tgt)\n",
    "                loss = self.loss(output.ravel(), y_out.ravel())\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "        \n",
    "        self.results['Test'].append(running_loss/len(test_loader))\n",
    "        \n",
    "    def early_stopping(self, validation_loader, decrease):\n",
    "        \n",
    "        loss_per_validation_batch = self.results['Validation'][-1]\n",
    "        min_loss = np.min(self.results['Validation'][:-1] + [np.inf])\n",
    "        if min_loss >= self.results['Validation'][-1]:\n",
    "            print('Loss Decreasing.. {:.3f} >> {:.3f} '.format(min_loss, loss_per_validation_batch))\n",
    "            decrease = self.patience\n",
    "            print('saving model...')\n",
    "            torch.save(model, self.path + '/Transformer.pt')\n",
    "        else:\n",
    "            decrease -= 1\n",
    "        if decrease < 0:\n",
    "                print('[***] end training ...')      \n",
    "                not_improved = 1\n",
    "        else:\n",
    "            not_improved = 0\n",
    "        return decrease, not_improved\n",
    "    \n",
    "    def get_best_model(self):\n",
    "        \n",
    "        model = torch.load(self.path + '/Transformer.pt')\n",
    "        return model\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Transformer(\n",
    "    num_outputs=1, dim_model=dataset.max_sequence, num_heads=8, \n",
    "    num_encoder_layers=6, num_decoder_layers=3, dropout_p=0.1, norm_first=True,num_linear_layers=0).to(device)\n",
    "\n",
    "lr_ = 1e-3\n",
    "epoch = 2000\n",
    "weight_decay = 1e-4\n",
    "path = '.'\n",
    "\n",
    "loss = torch.nn.MSELoss()\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=lr_)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=lr_)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr_, weight_decay=weight_decay)\n",
    "sched = None\n",
    "sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, lr_, epochs=epoch,\n",
    "                                            steps_per_epoch=len(train_loader))\n",
    "training = Training(epoch, loss, optimizer, sched, path, patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 47.06it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 287.44it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 298.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. inf >> 770678.519 \n",
      "saving model...\n",
      "Epoch:1/2000.. Train Loss: 982658.923.. Val Loss: 770678.519.. Test Loss: 654414.093.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 47.01it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 295.38it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 297.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 770678.519 >> 757664.071 \n",
      "saving model...\n",
      "Epoch:2/2000.. Train Loss: 908132.210.. Val Loss: 757664.071.. Test Loss: 586759.530.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 46.66it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 285.86it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 290.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 757664.071 >> 671494.794 \n",
      "saving model...\n",
      "Epoch:3/2000.. Train Loss: 836413.257.. Val Loss: 671494.794.. Test Loss: 552409.809.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 47.07it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 288.70it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 288.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 671494.794 >> 633090.332 \n",
      "saving model...\n",
      "Epoch:4/2000.. Train Loss: 771636.828.. Val Loss: 633090.332.. Test Loss: 512303.350.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.88it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 293.04it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 298.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 633090.332 >> 615241.496 \n",
      "saving model...\n",
      "Epoch:5/2000.. Train Loss: 727770.272.. Val Loss: 615241.496.. Test Loss: 502621.441.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 46.15it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 294.84it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 295.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 615241.496 >> 578893.082 \n",
      "saving model...\n",
      "Epoch:6/2000.. Train Loss: 678963.290.. Val Loss: 578893.082.. Test Loss: 495572.844.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 48.11it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 279.14it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 276.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 578893.082 >> 555111.188 \n",
      "saving model...\n",
      "Epoch:7/2000.. Train Loss: 640297.971.. Val Loss: 555111.188.. Test Loss: 446255.614.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 44.93it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 293.98it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 296.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 555111.188 >> 546200.337 \n",
      "saving model...\n",
      "Epoch:8/2000.. Train Loss: 607544.676.. Val Loss: 546200.337.. Test Loss: 416557.483.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.29it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 292.55it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 298.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 546200.337 >> 512332.227 \n",
      "saving model...\n",
      "Epoch:9/2000.. Train Loss: 574284.420.. Val Loss: 512332.227.. Test Loss: 397429.206.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.36it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 298.88it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 300.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 512332.227 >> 499401.173 \n",
      "saving model...\n",
      "Epoch:10/2000.. Train Loss: 543562.986.. Val Loss: 499401.173.. Test Loss: 390852.905.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 47.23it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 288.97it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 296.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 499401.173 >> 489467.389 \n",
      "saving model...\n",
      "Epoch:11/2000.. Train Loss: 519379.135.. Val Loss: 489467.389.. Test Loss: 364566.458.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.78it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 291.91it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 298.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 489467.389 >> 458919.589 \n",
      "saving model...\n",
      "Epoch:12/2000.. Train Loss: 495591.292.. Val Loss: 458919.589.. Test Loss: 350425.165.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.37it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 289.49it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 298.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 458919.589 >> 446308.628 \n",
      "saving model...\n",
      "Epoch:13/2000.. Train Loss: 477661.792.. Val Loss: 446308.628.. Test Loss: 336471.820.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 46.13it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 288.45it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 296.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 446308.628 >> 422324.857 \n",
      "saving model...\n",
      "Epoch:14/2000.. Train Loss: 454068.371.. Val Loss: 422324.857.. Test Loss: 336075.716.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.83it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 265.46it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 296.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:15/2000.. Train Loss: 438038.071.. Val Loss: 432780.676.. Test Loss: 317696.610.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.73it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 288.80it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 299.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 422324.857 >> 412800.036 \n",
      "saving model...\n",
      "Epoch:16/2000.. Train Loss: 424284.367.. Val Loss: 412800.036.. Test Loss: 310276.201.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 47.17it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 276.28it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 276.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:17/2000.. Train Loss: 404990.853.. Val Loss: 419941.680.. Test Loss: 307833.213.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.45it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 294.27it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 296.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 412800.036 >> 382938.560 \n",
      "saving model...\n",
      "Epoch:18/2000.. Train Loss: 393573.052.. Val Loss: 382938.560.. Test Loss: 289629.077.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 47.26it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 291.72it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 299.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 382938.560 >> 370056.568 \n",
      "saving model...\n",
      "Epoch:19/2000.. Train Loss: 379841.514.. Val Loss: 370056.568.. Test Loss: 283563.595.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.44it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 292.90it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 295.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 370056.568 >> 362614.201 \n",
      "saving model...\n",
      "Epoch:20/2000.. Train Loss: 367037.404.. Val Loss: 362614.201.. Test Loss: 273887.331.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 47.42it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 289.88it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 297.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 362614.201 >> 357991.596 \n",
      "saving model...\n",
      "Epoch:21/2000.. Train Loss: 354845.685.. Val Loss: 357991.596.. Test Loss: 271727.492.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 47.07it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 301.99it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 297.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 357991.596 >> 345111.753 \n",
      "saving model...\n",
      "Epoch:22/2000.. Train Loss: 342381.091.. Val Loss: 345111.753.. Test Loss: 270548.554.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 47.67it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 297.95it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 304.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 345111.753 >> 324817.864 \n",
      "saving model...\n",
      "Epoch:23/2000.. Train Loss: 332916.912.. Val Loss: 324817.864.. Test Loss: 265957.817.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 46.02it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 278.19it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 288.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 324817.864 >> 321638.099 \n",
      "saving model...\n",
      "Epoch:24/2000.. Train Loss: 321498.478.. Val Loss: 321638.099.. Test Loss: 245371.084.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.88it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 289.96it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 291.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 321638.099 >> 300224.139 \n",
      "saving model...\n",
      "Epoch:25/2000.. Train Loss: 311315.629.. Val Loss: 300224.139.. Test Loss: 233425.067.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.42it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 291.85it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 289.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:26/2000.. Train Loss: 303826.075.. Val Loss: 303953.962.. Test Loss: 229777.098.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 43.90it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 292.09it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 294.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 300224.139 >> 282059.038 \n",
      "saving model...\n",
      "Epoch:27/2000.. Train Loss: 293078.637.. Val Loss: 282059.038.. Test Loss: 217765.284.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.88it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 289.37it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 288.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 282059.038 >> 281574.628 \n",
      "saving model...\n",
      "Epoch:28/2000.. Train Loss: 286702.387.. Val Loss: 281574.628.. Test Loss: 214405.742.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 44.55it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 294.01it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 294.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 281574.628 >> 268646.172 \n",
      "saving model...\n",
      "Epoch:29/2000.. Train Loss: 276592.595.. Val Loss: 268646.172.. Test Loss: 207122.568.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 47.29it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 264.05it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 270.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:30/2000.. Train Loss: 271653.284.. Val Loss: 281912.004.. Test Loss: 213039.517.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 46.14it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 293.64it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 292.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 268646.172 >> 259333.985 \n",
      "saving model...\n",
      "Epoch:31/2000.. Train Loss: 264677.918.. Val Loss: 259333.985.. Test Loss: 197183.110.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 46.99it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 290.31it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 297.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 259333.985 >> 250372.085 \n",
      "saving model...\n",
      "Epoch:32/2000.. Train Loss: 254031.844.. Val Loss: 250372.085.. Test Loss: 195519.864.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 43.92it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 291.96it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 290.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:33/2000.. Train Loss: 249406.985.. Val Loss: 255103.701.. Test Loss: 187778.128.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 47.69it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 292.81it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 299.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 250372.085 >> 234283.998 \n",
      "saving model...\n",
      "Epoch:34/2000.. Train Loss: 241133.351.. Val Loss: 234283.998.. Test Loss: 179546.115.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.42it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 288.32it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 298.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 234283.998 >> 231062.620 \n",
      "saving model...\n",
      "Epoch:35/2000.. Train Loss: 233396.763.. Val Loss: 231062.620.. Test Loss: 184414.067.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 46.45it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 294.65it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 296.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 231062.620 >> 219056.828 \n",
      "saving model...\n",
      "Epoch:36/2000.. Train Loss: 226312.869.. Val Loss: 219056.828.. Test Loss: 169935.542.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 44.23it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 288.64it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 290.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:37/2000.. Train Loss: 220892.403.. Val Loss: 235469.552.. Test Loss: 165956.971.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.84it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 293.35it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 294.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 219056.828 >> 209002.640 \n",
      "saving model...\n",
      "Epoch:38/2000.. Train Loss: 216906.149.. Val Loss: 209002.640.. Test Loss: 165053.982.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 44.30it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 265.13it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 290.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 209002.640 >> 205749.363 \n",
      "saving model...\n",
      "Epoch:39/2000.. Train Loss: 209351.730.. Val Loss: 205749.363.. Test Loss: 163746.643.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 46.44it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 294.69it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 297.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 205749.363 >> 201807.841 \n",
      "saving model...\n",
      "Epoch:40/2000.. Train Loss: 205308.868.. Val Loss: 201807.841.. Test Loss: 154245.888.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 46.53it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 295.75it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 292.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 201807.841 >> 196939.359 \n",
      "saving model...\n",
      "Epoch:41/2000.. Train Loss: 198923.254.. Val Loss: 196939.359.. Test Loss: 153904.108.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 42.97it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 291.61it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 292.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 196939.359 >> 194314.737 \n",
      "saving model...\n",
      "Epoch:42/2000.. Train Loss: 194483.025.. Val Loss: 194314.737.. Test Loss: 154538.568.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 44.69it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 288.13it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 293.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 194314.737 >> 191598.791 \n",
      "saving model...\n",
      "Epoch:43/2000.. Train Loss: 190334.038.. Val Loss: 191598.791.. Test Loss: 143485.980.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 47.11it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 290.95it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 295.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 191598.791 >> 181543.163 \n",
      "saving model...\n",
      "Epoch:44/2000.. Train Loss: 184666.660.. Val Loss: 181543.163.. Test Loss: 148223.651.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.43it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 292.44it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 296.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 181543.163 >> 178400.286 \n",
      "saving model...\n",
      "Epoch:45/2000.. Train Loss: 182068.660.. Val Loss: 178400.286.. Test Loss: 137822.017.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 43.88it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 290.06it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 296.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 178400.286 >> 178289.668 \n",
      "saving model...\n",
      "Epoch:46/2000.. Train Loss: 176741.035.. Val Loss: 178289.668.. Test Loss: 140170.202.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 46.77it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 293.76it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 286.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 178289.668 >> 169055.194 \n",
      "saving model...\n",
      "Epoch:47/2000.. Train Loss: 174401.495.. Val Loss: 169055.194.. Test Loss: 133905.697.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 44.61it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 284.93it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 263.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 169055.194 >> 166103.904 \n",
      "saving model...\n",
      "Epoch:48/2000.. Train Loss: 170179.771.. Val Loss: 166103.904.. Test Loss: 131124.495.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 46.66it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 294.81it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 299.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:49/2000.. Train Loss: 166560.108.. Val Loss: 182592.158.. Test Loss: 129533.065.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.71it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 294.79it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 295.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 166103.904 >> 163889.585 \n",
      "saving model...\n",
      "Epoch:50/2000.. Train Loss: 164302.981.. Val Loss: 163889.585.. Test Loss: 125121.371.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 44.92it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 297.66it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 298.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 163889.585 >> 163632.431 \n",
      "saving model...\n",
      "Epoch:51/2000.. Train Loss: 158961.175.. Val Loss: 163632.431.. Test Loss: 123874.264.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.77it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 294.09it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 296.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 163632.431 >> 152440.853 \n",
      "saving model...\n",
      "Epoch:52/2000.. Train Loss: 154403.153.. Val Loss: 152440.853.. Test Loss: 123787.231.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.77it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 259.87it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 293.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:53/2000.. Train Loss: 153017.263.. Val Loss: 153013.072.. Test Loss: 121422.289.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.71it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 290.65it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 290.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 152440.853 >> 149486.113 \n",
      "saving model...\n",
      "Epoch:54/2000.. Train Loss: 150399.587.. Val Loss: 149486.113.. Test Loss: 119956.980.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 46.67it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 293.51it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 302.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 149486.113 >> 146139.986 \n",
      "saving model...\n",
      "Epoch:55/2000.. Train Loss: 147839.626.. Val Loss: 146139.986.. Test Loss: 119101.528.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.22it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 292.47it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 296.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 146139.986 >> 144244.738 \n",
      "saving model...\n",
      "Epoch:56/2000.. Train Loss: 143166.602.. Val Loss: 144244.738.. Test Loss: 117930.408.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 46.50it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 295.31it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 301.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 144244.738 >> 139468.766 \n",
      "saving model...\n",
      "Epoch:57/2000.. Train Loss: 140937.236.. Val Loss: 139468.766.. Test Loss: 111769.810.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 47.31it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 277.72it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 279.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:58/2000.. Train Loss: 139754.393.. Val Loss: 141843.486.. Test Loss: 110067.905.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 47.34it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 296.87it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 296.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 139468.766 >> 137995.082 \n",
      "saving model...\n",
      "Epoch:59/2000.. Train Loss: 135734.696.. Val Loss: 137995.082.. Test Loss: 110949.427.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.41it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 294.19it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 294.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 137995.082 >> 135526.174 \n",
      "saving model...\n",
      "Epoch:60/2000.. Train Loss: 133110.644.. Val Loss: 135526.174.. Test Loss: 108020.410.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.97it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 294.60it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 293.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:61/2000.. Train Loss: 130008.628.. Val Loss: 135794.545.. Test Loss: 115877.821.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 48.00it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 297.69it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 292.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:62/2000.. Train Loss: 127403.247.. Val Loss: 136646.720.. Test Loss: 111536.049.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 44.77it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 293.44it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 298.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 135526.174 >> 127744.332 \n",
      "saving model...\n",
      "Epoch:63/2000.. Train Loss: 127175.246.. Val Loss: 127744.332.. Test Loss: 103930.129.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 47.61it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 295.90it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 298.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:64/2000.. Train Loss: 123112.347.. Val Loss: 128781.977.. Test Loss: 102952.750.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 46.04it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 291.56it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 292.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 127744.332 >> 125975.897 \n",
      "saving model...\n",
      "Epoch:65/2000.. Train Loss: 120986.160.. Val Loss: 125975.897.. Test Loss: 103351.996.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 47.41it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 288.01it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 300.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 125975.897 >> 122622.423 \n",
      "saving model...\n",
      "Epoch:66/2000.. Train Loss: 118274.229.. Val Loss: 122622.423.. Test Loss: 100770.589.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 46.60it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 293.17it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 295.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 122622.423 >> 121291.389 \n",
      "saving model...\n",
      "Epoch:67/2000.. Train Loss: 116759.835.. Val Loss: 121291.389.. Test Loss: 99626.149.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 46.33it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 296.69it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 260.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:68/2000.. Train Loss: 117226.796.. Val Loss: 124203.890.. Test Loss: 99209.364.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 43.79it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 296.22it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 293.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 121291.389 >> 120831.242 \n",
      "saving model...\n",
      "Epoch:69/2000.. Train Loss: 113207.795.. Val Loss: 120831.242.. Test Loss: 99690.182.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 47.38it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 295.98it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 297.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 120831.242 >> 118047.114 \n",
      "saving model...\n",
      "Epoch:70/2000.. Train Loss: 112957.142.. Val Loss: 118047.114.. Test Loss: 97690.465.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.56it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 303.62it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 250.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:71/2000.. Train Loss: 109132.976.. Val Loss: 130841.943.. Test Loss: 98696.330.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.30it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 292.93it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 261.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 118047.114 >> 115697.660 \n",
      "saving model...\n",
      "Epoch:72/2000.. Train Loss: 110549.856.. Val Loss: 115697.660.. Test Loss: 96131.700.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.00it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 293.74it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 292.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:73/2000.. Train Loss: 105094.430.. Val Loss: 123011.186.. Test Loss: 106317.687.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 47.41it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 294.65it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 301.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 115697.660 >> 114781.683 \n",
      "saving model...\n",
      "Epoch:74/2000.. Train Loss: 105575.085.. Val Loss: 114781.683.. Test Loss: 94349.223.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 46.90it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 292.20it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 290.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 114781.683 >> 112642.531 \n",
      "saving model...\n",
      "Epoch:75/2000.. Train Loss: 101592.989.. Val Loss: 112642.531.. Test Loss: 94232.735.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.19it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 291.96it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 287.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 112642.531 >> 112047.043 \n",
      "saving model...\n",
      "Epoch:76/2000.. Train Loss: 100102.542.. Val Loss: 112047.043.. Test Loss: 104252.749.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.95it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 293.59it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 294.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 112047.043 >> 110287.827 \n",
      "saving model...\n",
      "Epoch:77/2000.. Train Loss: 102444.001.. Val Loss: 110287.827.. Test Loss: 93614.232.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 44.76it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 283.59it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 296.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:78/2000.. Train Loss: 97503.559.. Val Loss: 110373.840.. Test Loss: 97925.906.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 46.25it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 288.92it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 299.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 110287.827 >> 110233.306 \n",
      "saving model...\n",
      "Epoch:79/2000.. Train Loss: 96049.703.. Val Loss: 110233.306.. Test Loss: 92211.826.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.30it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 291.62it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 300.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:80/2000.. Train Loss: 94954.968.. Val Loss: 111126.207.. Test Loss: 98983.954.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 46.13it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 295.60it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 282.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 110233.306 >> 107800.385 \n",
      "saving model...\n",
      "Epoch:81/2000.. Train Loss: 95833.923.. Val Loss: 107800.385.. Test Loss: 92346.650.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.26it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 291.64it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 292.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 107800.385 >> 106709.539 \n",
      "saving model...\n",
      "Epoch:82/2000.. Train Loss: 92136.411.. Val Loss: 106709.539.. Test Loss: 91212.175.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 48.10it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 296.02it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 296.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:83/2000.. Train Loss: 91938.138.. Val Loss: 107780.229.. Test Loss: 93309.256.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 46.93it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 291.85it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 297.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:84/2000.. Train Loss: 90347.529.. Val Loss: 109745.331.. Test Loss: 92290.413.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 44.95it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 283.90it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 293.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 106709.539 >> 105167.751 \n",
      "saving model...\n",
      "Epoch:85/2000.. Train Loss: 89999.908.. Val Loss: 105167.751.. Test Loss: 92089.628.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.53it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 296.47it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 295.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:86/2000.. Train Loss: 89713.729.. Val Loss: 106887.661.. Test Loss: 89186.365.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 47.81it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 288.94it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 301.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 105167.751 >> 104158.174 \n",
      "saving model...\n",
      "Epoch:87/2000.. Train Loss: 87393.990.. Val Loss: 104158.174.. Test Loss: 88424.683.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 47.28it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 296.91it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 288.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:88/2000.. Train Loss: 85883.036.. Val Loss: 109876.170.. Test Loss: 95651.919.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.73it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 291.40it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 296.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:89/2000.. Train Loss: 84614.282.. Val Loss: 107673.515.. Test Loss: 88905.898.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 48.20it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 291.33it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 293.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:90/2000.. Train Loss: 83157.683.. Val Loss: 112809.264.. Test Loss: 88608.612.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 48.02it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 296.00it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 294.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 104158.174 >> 104023.546 \n",
      "saving model...\n",
      "Epoch:91/2000.. Train Loss: 84347.520.. Val Loss: 104023.546.. Test Loss: 88891.723.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 46.88it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 285.75it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 291.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 104023.546 >> 103141.432 \n",
      "saving model...\n",
      "Epoch:92/2000.. Train Loss: 80944.363.. Val Loss: 103141.432.. Test Loss: 97547.606.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.40it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 290.38it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 298.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 103141.432 >> 101595.787 \n",
      "saving model...\n",
      "Epoch:93/2000.. Train Loss: 81840.187.. Val Loss: 101595.787.. Test Loss: 86458.169.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 46.65it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 294.40it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 299.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:94/2000.. Train Loss: 81145.577.. Val Loss: 104104.403.. Test Loss: 89635.065.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 46.93it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 295.25it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 296.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:95/2000.. Train Loss: 78959.570.. Val Loss: 101792.957.. Test Loss: 91832.599.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 46.26it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 292.46it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 290.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 101595.787 >> 100383.872 \n",
      "saving model...\n",
      "Epoch:96/2000.. Train Loss: 77854.364.. Val Loss: 100383.872.. Test Loss: 87147.766.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 46.00it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 289.61it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 281.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:97/2000.. Train Loss: 76926.988.. Val Loss: 107700.486.. Test Loss: 96638.168.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.10it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 289.16it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 295.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:98/2000.. Train Loss: 75968.039.. Val Loss: 102915.571.. Test Loss: 89767.003.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.10it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 295.77it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 294.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 100383.872 >> 100153.677 \n",
      "saving model...\n",
      "Epoch:99/2000.. Train Loss: 76720.824.. Val Loss: 100153.677.. Test Loss: 89325.193.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 46.15it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 294.15it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 296.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:100/2000.. Train Loss: 74093.450.. Val Loss: 100830.507.. Test Loss: 85065.025.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 46.62it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 291.92it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 290.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 100153.677 >> 98358.778 \n",
      "saving model...\n",
      "Epoch:101/2000.. Train Loss: 74842.842.. Val Loss: 98358.778.. Test Loss: 87047.738.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 44.88it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 288.42it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 293.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:102/2000.. Train Loss: 72446.084.. Val Loss: 112458.142.. Test Loss: 88671.005.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.68it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 288.06it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 296.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:103/2000.. Train Loss: 71674.022.. Val Loss: 100589.169.. Test Loss: 90872.717.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 47.21it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 292.93it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 299.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 98358.778 >> 97817.145 \n",
      "saving model...\n",
      "Epoch:104/2000.. Train Loss: 72361.946.. Val Loss: 97817.145.. Test Loss: 85341.635.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.97it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 245.19it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 277.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:105/2000.. Train Loss: 70115.010.. Val Loss: 101086.030.. Test Loss: 84164.830.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.01it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 291.33it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 258.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:106/2000.. Train Loss: 69499.798.. Val Loss: 98793.655.. Test Loss: 85044.398.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 47.45it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 256.06it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 299.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:107/2000.. Train Loss: 70345.874.. Val Loss: 98735.208.. Test Loss: 84949.191.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.83it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 292.48it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 299.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:108/2000.. Train Loss: 67663.383.. Val Loss: 98090.536.. Test Loss: 83264.735.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 47.61it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 290.17it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 291.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 97817.145 >> 95783.305 \n",
      "saving model...\n",
      "Epoch:109/2000.. Train Loss: 68295.717.. Val Loss: 95783.305.. Test Loss: 83084.201.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 46.21it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 291.51it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 299.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:110/2000.. Train Loss: 66224.188.. Val Loss: 99774.597.. Test Loss: 82992.107.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.39it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 294.05it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 300.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:111/2000.. Train Loss: 66243.496.. Val Loss: 113650.398.. Test Loss: 82865.148.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.69it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 292.64it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 287.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:112/2000.. Train Loss: 65471.948.. Val Loss: 102452.641.. Test Loss: 83173.217.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 46.64it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 295.32it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 292.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:113/2000.. Train Loss: 65080.796.. Val Loss: 97861.430.. Test Loss: 81888.919.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 46.59it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 297.85it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 256.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:114/2000.. Train Loss: 64354.943.. Val Loss: 98413.732.. Test Loss: 82242.937.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 46.09it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 290.96it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 299.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 95783.305 >> 93981.806 \n",
      "saving model...\n",
      "Epoch:115/2000.. Train Loss: 63643.882.. Val Loss: 93981.806.. Test Loss: 81545.641.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 47.10it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 296.15it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 292.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:116/2000.. Train Loss: 62760.337.. Val Loss: 97891.603.. Test Loss: 88750.795.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 47.07it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 289.25it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 257.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:117/2000.. Train Loss: 62334.551.. Val Loss: 109077.277.. Test Loss: 81581.441.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 44.48it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 293.51it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 293.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:118/2000.. Train Loss: 61335.063.. Val Loss: 94186.300.. Test Loss: 81137.638.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 43.10it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 270.48it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 274.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:119/2000.. Train Loss: 60945.599.. Val Loss: 107529.175.. Test Loss: 82077.299.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 44.68it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 290.07it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 296.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:120/2000.. Train Loss: 60476.665.. Val Loss: 107095.281.. Test Loss: 80534.450.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 43.57it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 290.88it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 293.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 93981.806 >> 93189.071 \n",
      "saving model...\n",
      "Epoch:121/2000.. Train Loss: 59675.665.. Val Loss: 93189.071.. Test Loss: 80675.876.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 44.58it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 295.64it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 297.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:122/2000.. Train Loss: 59447.304.. Val Loss: 113467.031.. Test Loss: 80641.156.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.74it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 251.70it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 293.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 93189.071 >> 92443.213 \n",
      "saving model...\n",
      "Epoch:123/2000.. Train Loss: 59017.777.. Val Loss: 92443.213.. Test Loss: 86313.296.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.36it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 290.11it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 302.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 92443.213 >> 92336.788 \n",
      "saving model...\n",
      "Epoch:124/2000.. Train Loss: 58330.123.. Val Loss: 92336.788.. Test Loss: 82092.570.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.25it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 286.66it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 297.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 92336.788 >> 91667.083 \n",
      "saving model...\n",
      "Epoch:125/2000.. Train Loss: 56516.087.. Val Loss: 91667.083.. Test Loss: 81651.500.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.67it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 289.58it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 297.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:126/2000.. Train Loss: 56814.369.. Val Loss: 92248.695.. Test Loss: 80354.014.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.12it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 295.26it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 295.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:127/2000.. Train Loss: 55793.180.. Val Loss: 92314.652.. Test Loss: 80111.706.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 44.89it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 280.76it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 284.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 91667.083 >> 91438.098 \n",
      "saving model...\n",
      "Epoch:128/2000.. Train Loss: 56327.130.. Val Loss: 91438.098.. Test Loss: 87593.491.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 44.16it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 286.58it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 292.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:129/2000.. Train Loss: 55596.785.. Val Loss: 93386.795.. Test Loss: 78258.204.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.04it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 288.43it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 290.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:130/2000.. Train Loss: 56149.297.. Val Loss: 91440.958.. Test Loss: 94656.888.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 44.71it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 287.51it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 288.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:131/2000.. Train Loss: 55718.231.. Val Loss: 93205.298.. Test Loss: 77763.450.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 44.32it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 290.17it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 295.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:132/2000.. Train Loss: 55076.631.. Val Loss: 93038.380.. Test Loss: 77872.550.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 44.01it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 297.58it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 290.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:133/2000.. Train Loss: 53915.898.. Val Loss: 92757.669.. Test Loss: 77134.159.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 44.88it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 291.02it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 288.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:134/2000.. Train Loss: 54351.673.. Val Loss: 92364.895.. Test Loss: 84067.554.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.89it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 283.96it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 288.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 91438.098 >> 90949.359 \n",
      "saving model...\n",
      "Epoch:135/2000.. Train Loss: 52545.797.. Val Loss: 90949.359.. Test Loss: 78305.797.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 44.98it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 289.58it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 289.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:136/2000.. Train Loss: 53573.704.. Val Loss: 96608.563.. Test Loss: 79566.067.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.97it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 256.68it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 290.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:137/2000.. Train Loss: 52438.794.. Val Loss: 90990.538.. Test Loss: 77740.660.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 46.59it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 294.17it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 294.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 90949.359 >> 90664.516 \n",
      "saving model...\n",
      "Epoch:138/2000.. Train Loss: 51229.786.. Val Loss: 90664.516.. Test Loss: 87697.665.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.79it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 291.04it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 294.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:139/2000.. Train Loss: 51251.908.. Val Loss: 92726.274.. Test Loss: 76998.221.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 46.23it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 287.59it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 289.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:140/2000.. Train Loss: 50879.381.. Val Loss: 94131.652.. Test Loss: 77540.485.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 44.20it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 288.96it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 295.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:141/2000.. Train Loss: 49956.206.. Val Loss: 94761.767.. Test Loss: 76588.767.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 44.80it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 293.28it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 295.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:142/2000.. Train Loss: 50267.430.. Val Loss: 94070.053.. Test Loss: 77935.499.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 46.99it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 293.55it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 299.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 90664.516 >> 90205.636 \n",
      "saving model...\n",
      "Epoch:143/2000.. Train Loss: 49743.764.. Val Loss: 90205.636.. Test Loss: 75576.341.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 44.98it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 285.74it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 292.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:144/2000.. Train Loss: 49686.054.. Val Loss: 90728.030.. Test Loss: 76008.087.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 44.33it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 295.76it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 294.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:145/2000.. Train Loss: 50680.611.. Val Loss: 104273.874.. Test Loss: 75800.719.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 46.13it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 293.25it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 295.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:146/2000.. Train Loss: 48444.694.. Val Loss: 92699.777.. Test Loss: 75556.023.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 47.38it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 294.99it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 297.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:147/2000.. Train Loss: 48123.405.. Val Loss: 97429.576.. Test Loss: 75909.034.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 44.67it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 295.33it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 297.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:148/2000.. Train Loss: 47819.798.. Val Loss: 92640.528.. Test Loss: 75293.875.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 47.54it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 288.96it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 251.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 90205.636 >> 90105.286 \n",
      "saving model...\n",
      "Epoch:149/2000.. Train Loss: 47284.802.. Val Loss: 90105.286.. Test Loss: 75891.918.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.62it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 296.80it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 298.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 90105.286 >> 90014.522 \n",
      "saving model...\n",
      "Epoch:150/2000.. Train Loss: 47370.061.. Val Loss: 90014.522.. Test Loss: 75095.373.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 44.90it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 290.64it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 292.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 90014.522 >> 89661.383 \n",
      "saving model...\n",
      "Epoch:151/2000.. Train Loss: 47976.332.. Val Loss: 89661.383.. Test Loss: 82062.182.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 47.05it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 287.74it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 291.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:152/2000.. Train Loss: 47124.974.. Val Loss: 94050.894.. Test Loss: 90786.295.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.84it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 286.95it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 258.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:153/2000.. Train Loss: 47017.228.. Val Loss: 115147.730.. Test Loss: 74566.601.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.42it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 283.28it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 299.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:154/2000.. Train Loss: 46651.653.. Val Loss: 92694.753.. Test Loss: 74479.083.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.53it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 288.15it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 296.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 89661.383 >> 88121.893 \n",
      "saving model...\n",
      "Epoch:155/2000.. Train Loss: 47472.684.. Val Loss: 88121.893.. Test Loss: 78666.724.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 47.35it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 295.17it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 290.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:156/2000.. Train Loss: 47293.218.. Val Loss: 116230.620.. Test Loss: 72683.247.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 47.02it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 293.44it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 298.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:157/2000.. Train Loss: 46396.204.. Val Loss: 89245.456.. Test Loss: 74032.286.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 44.20it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 289.56it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 291.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:158/2000.. Train Loss: 45174.437.. Val Loss: 88154.237.. Test Loss: 73835.063.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.10it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 294.64it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 293.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:159/2000.. Train Loss: 44420.301.. Val Loss: 90493.203.. Test Loss: 75975.617.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 46.07it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 293.71it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 298.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:160/2000.. Train Loss: 43953.143.. Val Loss: 89684.927.. Test Loss: 75584.002.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 46.55it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 287.33it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 290.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:161/2000.. Train Loss: 43441.462.. Val Loss: 89098.827.. Test Loss: 74668.041.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 46.44it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 265.13it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 292.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:162/2000.. Train Loss: 42925.607.. Val Loss: 93282.211.. Test Loss: 74037.278.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.79it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 292.82it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 294.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:163/2000.. Train Loss: 43595.719.. Val Loss: 89695.974.. Test Loss: 73168.741.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.41it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 253.99it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 288.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:164/2000.. Train Loss: 43187.796.. Val Loss: 89065.906.. Test Loss: 74216.391.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 46.50it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 299.35it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 291.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:165/2000.. Train Loss: 41583.655.. Val Loss: 88134.111.. Test Loss: 75294.857.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 46.22it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 293.33it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 292.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:166/2000.. Train Loss: 41433.421.. Val Loss: 91125.203.. Test Loss: 81866.206.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.82it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 287.50it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 298.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:167/2000.. Train Loss: 41165.294.. Val Loss: 93655.862.. Test Loss: 88104.326.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.49it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 290.01it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 297.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:168/2000.. Train Loss: 40766.682.. Val Loss: 105959.889.. Test Loss: 73221.403.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 47.40it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 291.53it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 297.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 88121.893 >> 87573.477 \n",
      "saving model...\n",
      "Epoch:169/2000.. Train Loss: 41485.544.. Val Loss: 87573.477.. Test Loss: 89298.132.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 47.40it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 294.25it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 292.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:170/2000.. Train Loss: 40695.971.. Val Loss: 89398.041.. Test Loss: 73671.055.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 46.16it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 296.07it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 247.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:171/2000.. Train Loss: 41693.467.. Val Loss: 88561.398.. Test Loss: 77672.608.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 43.54it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 294.73it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 298.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:172/2000.. Train Loss: 40921.464.. Val Loss: 91435.846.. Test Loss: 72023.162.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 46.55it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 293.83it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 301.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:173/2000.. Train Loss: 41988.788.. Val Loss: 92763.638.. Test Loss: 72501.194.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 46.06it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 293.40it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 294.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:174/2000.. Train Loss: 39480.256.. Val Loss: 89268.141.. Test Loss: 73761.696.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 47.06it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 288.74it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 297.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:175/2000.. Train Loss: 40128.165.. Val Loss: 89065.704.. Test Loss: 74403.406.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.78it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 262.27it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 291.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:176/2000.. Train Loss: 39253.259.. Val Loss: 87892.224.. Test Loss: 73088.042.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 44.99it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 288.44it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 295.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:177/2000.. Train Loss: 38037.912.. Val Loss: 93226.802.. Test Loss: 72324.455.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 44.63it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 289.23it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 293.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:178/2000.. Train Loss: 38119.374.. Val Loss: 90847.263.. Test Loss: 73434.576.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 46.27it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 293.02it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 299.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:179/2000.. Train Loss: 39015.719.. Val Loss: 110495.100.. Test Loss: 72017.867.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 42.34it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 295.07it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 292.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:180/2000.. Train Loss: 37600.057.. Val Loss: 95240.488.. Test Loss: 73226.626.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 46.28it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 294.94it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 292.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:181/2000.. Train Loss: 38277.809.. Val Loss: 88489.515.. Test Loss: 71943.094.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 45.77it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 294.95it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 296.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:182/2000.. Train Loss: 36519.414.. Val Loss: 94823.079.. Test Loss: 72748.697.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 46.50it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 282.21it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 296.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:183/2000.. Train Loss: 36694.488.. Val Loss: 89636.554.. Test Loss: 72757.452.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 47.65it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 296.78it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 300.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:184/2000.. Train Loss: 35847.547.. Val Loss: 103487.757.. Test Loss: 71239.210.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 43.08it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 284.62it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 293.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:185/2000.. Train Loss: 35428.865.. Val Loss: 90439.342.. Test Loss: 73837.606.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 46.80it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 294.66it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 291.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:186/2000.. Train Loss: 35944.133.. Val Loss: 91733.290.. Test Loss: 71908.619.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 47.89it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 291.38it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 299.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:187/2000.. Train Loss: 35317.965.. Val Loss: 90849.958.. Test Loss: 79046.743.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 46.84it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 292.67it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 297.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:188/2000.. Train Loss: 35902.488.. Val Loss: 95387.950.. Test Loss: 77482.828.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 44.67it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 296.42it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 288.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:189/2000.. Train Loss: 36389.006.. Val Loss: 88006.733.. Test Loss: 73722.022.. Time: 0.02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:01<00:00, 44.60it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 291.93it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 296.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[***] end training ...\n",
      "Total time: 4.13 m\n"
     ]
    }
   ],
   "source": [
    "training.fit(model, train_loader, validation_loader, test_loader)\n",
    "model = training.get_best_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2b37cde047f0>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(training.results['Train'], label='Train')\n",
    "ax.plot(training.results['Validation'], label='Validation')\n",
    "ax.plot(training.results['Test'], label='Test')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation and plotting classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class OSAEvaluator:\n",
    "    \n",
    "    def evaluate_OSA(self, dataset, model):\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        Y_real = []\n",
    "        Y_pred = []\n",
    "        for i, data in enumerate(tqdm(dataset)):\n",
    "            src, tgt, y_real = data\n",
    "            src, tgt, y_real = src.to(device), tgt.to(device), y_real.to(device)\n",
    "            y_pred = model(src, tgt)\n",
    "            Y_real.append(y_real.reshape(1,-1))\n",
    "            Y_pred.append(y_pred)\n",
    "        \n",
    "        Y_real = torch.vstack(Y_real).cpu()\n",
    "        Y_pred = torch.vstack(Y_pred).cpu().detach()\n",
    "        return Y_real, Y_pred\n",
    "            \n",
    "class FSEvaluator:\n",
    "    \n",
    "    def evaluate_FS(self, dataset, model):\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        Y_real = []\n",
    "        Y_pred = []\n",
    "        tgt_sim = None\n",
    "        for i, data in enumerate(tqdm(dataset)):\n",
    "            src, tgt, y_real = data\n",
    "            src, tgt, y_real = src.to(device), tgt.to(device), y_real.to(device)\n",
    "            if tgt_sim is None:\n",
    "                tgt_sim = tgt\n",
    "            else:\n",
    "                tgt_sim[:-1,:] = tgt_sim[1:,:]\n",
    "                tgt_sim[-1,:] = y_pred\n",
    "            y_pred = model(src, tgt_sim)\n",
    "            Y_real.append(y_real.reshape(1,-1))\n",
    "            Y_pred.append(y_pred)\n",
    "        \n",
    "        Y_real = torch.vstack(Y_real).cpu()\n",
    "        Y_pred = torch.vstack(Y_pred).cpu().detach()\n",
    "        return Y_real, Y_pred\n",
    "    \n",
    "class Evaluator(OSAEvaluator, FSEvaluator):\n",
    "    \n",
    "    pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 699/699 [00:04<00:00, 167.72it/s]\n",
      "100%|██████████| 699/699 [00:03<00:00, 209.03it/s]\n"
     ]
    }
   ],
   "source": [
    "evaluator = Evaluator()\n",
    "Y_real, Y_pred_OSA = evaluator.evaluate_OSA(dataset, model)\n",
    "Y_real, Y_pred_FS = evaluator.evaluate_FS(dataset, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2b37cd5e79a0>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(Y_real, label='Real')\n",
    "ax.plot(Y_pred_OSA, label='OSA')\n",
    "ax.plot(Y_pred_FS, label='FS')\n",
    "ax.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "raul_dl",
   "language": "python",
   "name": "raul_dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
